{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import requests\n",
    "from config import news_key\n",
    "from newsapi import NewsApiClient\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We dynamically generating last 30 days\n",
    "dates = []\n",
    "for x in range(31):\n",
    "    dates.append(datetime.now() - timedelta(days=x))\n",
    "\n",
    "print(str(dates[30])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up NewsAPI client\n",
    "newsapi = NewsApiClient(api_key=news_key)\n",
    "\n",
    "# Create empty arrays to receive responses\n",
    "headline = []\n",
    "date = []\n",
    "description = []\n",
    "\n",
    "#Search the NewsAPI for articles about a company\n",
    "for x in range(1,50):\n",
    "    amazon_articles = newsapi.get_everything(q='Amazon',\n",
    "                                      from_param= str(dates[28])[:10],\n",
    "                                      to=str(dates[27])[:10],\n",
    "                                      language='en',\n",
    "                                      sort_by='relevancy', page=x)\n",
    "\n",
    "    #Output headline names, date, and description\n",
    "    for i in range(len(amazon_articles[\"articles\"])):\n",
    "        headline.append(amazon_articles[\"articles\"][i][\"title\"])\n",
    "        date.append(amazon_articles[\"articles\"][i][\"publishedAt\"])\n",
    "        description.append(amazon_articles[\"articles\"][i][\"description\"])                              \n",
    "    #request the headline\n",
    "\n",
    "        #loop through entities and check for type 2\n",
    "        #append the text of the type 2 entity to Organization column\n",
    "        #if an org is found in the headline go to next loop\n",
    "        #if its not loop through description\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(headline).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the company name of each headline\n",
    "#Put the other information into an array for main Datafame\n",
    "company = []\n",
    "company_headline = []\n",
    "company_date = []\n",
    "company_sentiment = []\n",
    "for i in range(5):\n",
    "    request = requests.post(\"http://api.intellexer.com/recognizeNeText?apikey=fbe3ac25-304d-4384-aeb8-4bc2c32568e4&loadNamedEntities=true&loadRelationsTree=False&loadSentences=true\", data= f\"{headline[i] + description[i]}\".encode('utf-8')).json()\n",
    "    for y in range(len(request[\"entities\"])):\n",
    "        try:\n",
    "            if request['entities'][y][\"type\"]== 2 and request['entities'][y][\"text\"] == \"Amazon\":\n",
    "                company.append(request[\"entities\"][y][\"text\"])\n",
    "                company_headline.append(headline[i])\n",
    "                company_date.append(date[y][:10])\n",
    "                \n",
    "                #Request the sentiment\n",
    "                sentiment = requests.post(\"http://api.intellexer.com/analyzeSentiments?apikey=fbe3ac25-304d-4384-aeb8-4bc2c32568e4&loadNamedEntities=true&loadRelationsTree=False&loadSentences=true\", data= f\"{headline[i] + description[i]}\".encode('utf-8')).json()\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "print(len(organization))                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request['sentences'][0][:len(headline[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_cols = {\"Headline\": company_headline,\n",
    "                \"Company\": company,\n",
    "                \"Date\": company_date}\n",
    "company_data = pd.DataFrame(company_cols)\n",
    "company_data.head()\n",
    "headline[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We removed time stamp from PublishedAT column\n",
    "published_date = []\n",
    "\n",
    "for x in range(len(date)):\n",
    "    published_date.append(str(date[x])[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Headline\":headline, \"PublishedAt\":published_date, \"Description\":description})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = requests.post(\"http://api.intellexer.com/recognizeNeText?apikey=fbe3ac25-304d-4384-aeb8-4bc2c32568e4&loadNamedEntities=true&loadRelationsTree=true&loadSentences=true\", data=[{\"id\": \"snt1\",\"text\": \"Bill is a very nice guy\"}]).json()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4cd6621c6cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "payload = json.dumps({\"id\":\"headline1\",\"text\":\"Amazon is the best company ever\"})\n",
    "url = \"http://api.intellexer.com/analyzeSentiments?apikey=fbe3ac25-304d-4384-aeb8-4bc2c32568e4&ontology=hotels&loadSentences=true\"\n",
    "sentiment = requests.post(url, data=payload, headers = {'Content-type':'application/json'}) \n",
    "print(sentiment.status_code)\n",
    "\n",
    "\n",
    "\n",
    "payload.type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies = requests.get(\"http://api.intellexer.com/sentimentAnalyzerOntologies?apikey=fbe3ac25-304d-4384-aeb8-4bc2c32568e4\").json()\n",
    "ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
