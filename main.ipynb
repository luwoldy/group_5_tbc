{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import requests\n",
    "from config import news_key, int_key\n",
    "from newsapi import NewsApiClient\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only weekdays in an array so we can search the News API\n",
    "Tickers= [\"AAPL\", \"BRK.A\", \"JPM\", \"XOM\", \"T\", \"BAC\", \"WFC\", \"VZ\", \"MSFT\", \"WMT\", \"GOOGL\", \"AMZN\"]\n",
    "stock = requests.get(f\"https://api.iextrading.com/1.0/stock/{Tickers[0]}/chart/1m\")\n",
    "stocks = stock.json()\n",
    "dates = []\n",
    "\n",
    "for i in range(len(stocks)):\n",
    "    dates.append(stocks[i][\"date\"])\n",
    "#take off the first date if we are outside of the news API date frame\n",
    "dates.remove(dates[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies= [\"Apple\", \"Berkshire Hathaway\", \"JP Morgan Chase\", \"ExxonMobil\", \"AT&T\", \"Bank of America\", \"Wells Fargo\", \n",
    "            \"Verizon\", \"Microsoft\", \"Wal-Mart\", \"Alphabet\", \"Amazon\"  ]\n",
    "def get_company_data(company_name,p):\n",
    "    # Set up NewsAPI client\n",
    "    newsapi = NewsApiClient(api_key=news_key)\n",
    "\n",
    "    # Create empty arrays to receive responses\n",
    "    headline = []\n",
    "    date_published = []\n",
    "    description = []\n",
    "\n",
    "    #Search the NewsAPI for articles about a company on stock days\n",
    "    #Loop through X number of pages, up to 50\n",
    "    for x in range(1,p):\n",
    "        for date in dates:\n",
    "            amazon_articles = newsapi.get_everything(q=f\"{company_name}\",\n",
    "                                              from_param= date,\n",
    "                                              to= date,\n",
    "                                              language='en',\n",
    "                                              sort_by='relevancy', page=x)\n",
    "\n",
    "        #Output headline names, date, and description\n",
    "        for i in range(len(amazon_articles[\"articles\"])):\n",
    "            headline.append(amazon_articles[\"articles\"][i][\"title\"])\n",
    "            date_published.append(amazon_articles[\"articles\"][i][\"publishedAt\"])\n",
    "            description.append(amazon_articles[\"articles\"][i][\"description\"])                              \n",
    "    #Find the company name of each headline\n",
    "    #Put the other information into an array for main Datafame\n",
    "    company = []\n",
    "    company_headline = []\n",
    "    company_date = []\n",
    "    company_sentiment = []\n",
    "    #Loop through X number of  headlines. change to len(headline) when ready\n",
    "    for i in range(10):\n",
    "        request = requests.post(f\"http://api.intellexer.com/recognizeNeText?apikey={int_key}&loadNamedEntities=true&loadRelationsTree=False&loadSentences=true\", data= f\"{headline[i] + description[i]}\".encode('utf-8')).json()\n",
    "        for y in range(len(request[\"entities\"])):\n",
    "            try:\n",
    "                if request['entities'][y][\"type\"]== 2 and request['entities'][y][\"text\"] == f\"{company_name}\":\n",
    "                    company.append(request[\"entities\"][y][\"text\"])\n",
    "                    company_headline.append(headline[i])\n",
    "                    company_date.append(date_published[i][:10])\n",
    "\n",
    "                    #Request the sentiment\n",
    "                    url = f\"http://api.intellexer.com/analyzeSentiments?apikey={int_key}\"\n",
    "                    sentiment = requests.post(url, data= json.dumps([{\"id\": \"1\", \"text\": headline[i] + description[i]}]),headers = {\"Content-Type\": \"application/json\", \"Cache-Control\": \"no-cache\"}).json()\n",
    "                    company_sentiment.append(float(sentiment['sentiments'][0]['w']))\n",
    "\n",
    "                    break\n",
    "                else: \n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "    company_cols = {\"Headline\": company_headline,\n",
    "                \"Company\": company,\n",
    "                \"Date\": company_date,\n",
    "                \"Sentiment\": company_sentiment}\n",
    "    company_data = pd.DataFrame(company_cols)\n",
    "    #export to csv when ready\n",
    "    company_data.to_csv(f\"{company_name}_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this function with company name and number of pages\n",
    "get_company_data(companies[0],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output all company csv's, get all pages\n",
    "#for company_name in companies:\n",
    "#    get_company_data(company_name,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_csv(ticker):\n",
    "    change = []\n",
    "    stock_date = []\n",
    "    date = []\n",
    "    stock = requests.get(f\"https://api.iextrading.com/1.0/stock/{ticker}/chart/1m\")\n",
    "    stocks = stock.json()\n",
    "    \n",
    "    for i in range(len(stocks)):\n",
    "        change.append(stocks[i]['changePercent'])\n",
    "        stock_date.append(stocks[i]['date'])\n",
    "    stocks_df = pd.DataFrame({\"Date\":stock_date, \"Percent Change\": change})\n",
    "    #print to csv when ready\n",
    "    #stocks_df.to_csv(f\"{ticker}.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out CSV's for each company \n",
    "\n",
    "for ticker in Tickers:\n",
    "    get_stock_csv(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
